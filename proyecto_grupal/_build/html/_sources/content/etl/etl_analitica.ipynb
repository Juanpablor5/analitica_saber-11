{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flujo del proceso ETL\n",
    "\n",
    "## Extract\n",
    "\n",
    "Para el proceso de Extracción, se recopilaron los datos de las pruebas Saber 11 proporcionados por el Instituto Colombiano para la Evaluación de la Educación (ICFES), disponibles en Datos Abiertos de Colombia. Esta base de datos, actualizada el 20 de abril de 2024, contiene más de 7,11 millones de observaciones distribuidas en 51 columnas.\n",
    "\n",
    "La extracción de estos datos involucró la utilización de técnicas de tratamiento de datos estructurados (CSV). Los datos, proporcionados por el ICFES y gestionados a través de la Oficina Asesora de Investigaciones, fueron descargados y procesados utilizando herramientas herramientas como Dbeaver, Docker y Python. Esto establece una base sólida para las etapas posteriores del proceso de análisis de datos, como la transformación, visualización y aplicación de técnicas de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las librerías que usaremos son:\n",
    "- pandas: para la manipulación de datos\n",
    "- sqlalchemy: para la conexión con la base de datos\n",
    "- prefect: para la creación de pipelines y la orquestación de tareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.orm import declarative_base, Session\n",
    "from prefect import task, flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se creaó el diccionario `config_bd`, el cual contiene los datos de conexión a la base de datos local y remota de AWS. Ambas bases de datos están bajo el motor PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bd = {\n",
    "    \"local\": {\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"5432\",\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"postgres\",\n",
    "        \"database\": \"juan_rocha\",\n",
    "    },\n",
    "    \"aws\": {\n",
    "        \"host\": \"postgres.cspcvpb5rw4y.us-east-1.rds.amazonaws.com\",\n",
    "        \"port\": \"5432\",\n",
    "        \"user\": \"jrocha\",\n",
    "        \"password\": \"fjwvacC_d6iupULVdyK7\",\n",
    "        \"database\": \"analitica\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `config_conexion` es un decorador que permite la conexión a la base de datos de manera dinámica según el entorno en el que se esté trabajando, (local o aws)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_conexion(func):\n",
    "    def inner(tipo, *args, **kwargs):\n",
    "        data = config_bd[tipo]\n",
    "        return func(data, *args, **kwargs)\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función `conectar_bd`, se establece la conexión a la base de datos. Para definir cuál tipo de conexión se va a realizar, se debe agregar el decorador `@config_conexion`, y recibir como parámetro el la llave del diccionario `config_bd` que se desea utilizar. Adicionalmente, se configura el decorador @task para que la función sea reconocida por Prefect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config_conexion\n",
    "@task\n",
    "def conectar_bd(env_data):\n",
    "    print(f'connected to {env_data[\"database\"]} db')\n",
    "\n",
    "    host = env_data[\"host\"]\n",
    "    port = env_data[\"port\"]\n",
    "    user = env_data[\"user\"]\n",
    "    password = env_data[\"password\"]\n",
    "    database = env_data[\"database\"]\n",
    "\n",
    "    return sa.create_engine(\n",
    "        f\"postgresql://{user}:{password}@{host}:{port}/{database}\", echo=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "Para la fase de Transformación, se emplearon SQL Alchemy y Pandas para realizar consultas y manipular los datos. A través de estas herramientas, se realizaron diferentes consultas para obtener varios DataFrames específicos, que permiten un análisis más enfocado en distintas áreas de interés. Estos DataFrames incluyen:\n",
    "\n",
    "- `analitica_colegio`: Análisis enfocado en las características y desempeño de los colegios.\n",
    "- `analitica_educacion_familia`: Análisis de la influencia del nivel educativo de la familia en los resultados.\n",
    "- `analitica_puntaje_estrato`: Evaluación de la relación entre el puntaje y el estrato socioeconómico.\n",
    "- `analitica_puntaje_genero`: Comparación de puntajes entre géneros.\n",
    "- `analitica_puntaje_internet`: Análisis del impacto del acceso a internet en los puntajes.\n",
    "- `analitica_puntaje_periodo`: Evaluación de los puntajes en diferentes periodos.\n",
    "\n",
    "Estos DataFrames proporcionan una visión detallada y segmentada de los datos, facilitando la identificación de patrones y tendencias específicos que pueden ser cruciales para comprender los factores que influyen en los resultados de las pruebas Saber 11.\n",
    "\n",
    "Las funciones `obtener_datos_colegio` y `obtener_datos_estudiante` se encargan de realizar las consultas a la base de datos y retornar los DataFrames correspondientes. Estas funciones se decoran con `@task` para que sean reconocidas por Prefect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_datos_colegio(env):\n",
    "    conn = conectar_bd(env)\n",
    "    sql_query = \"\"\"\n",
    "        select\n",
    "            s.cole_cod_dane_establecimiento,\n",
    "            s.cole_jornada,\n",
    "            s.cole_naturaleza,\n",
    "            s.cole_calendario,\n",
    "            s.cole_nombre_establecimiento,\n",
    "            s.cole_caracter,\n",
    "            s.cole_area_ubicacion,\n",
    "            s.cole_genero,\n",
    "            AVG(s.punt_global) as prom_punt_global\n",
    "        from\n",
    "            saber_11 s\n",
    "        group by\n",
    "            s.cole_cod_dane_establecimiento,\n",
    "            s.cole_jornada,\n",
    "            s.cole_naturaleza,\n",
    "            s.cole_calendario,\n",
    "            s.cole_nombre_establecimiento,\n",
    "            s.cole_caracter,\n",
    "            s.cole_area_ubicacion,\n",
    "            s.cole_genero\n",
    "        order by\n",
    "            prom_punt_global desc;\n",
    "      \"\"\"\n",
    "    datos_colegio = pd.read_sql_query(sql_query, con=conn)\n",
    "\n",
    "    conn.dispose()\n",
    "    return datos_colegio\n",
    "\n",
    "def obtener_datos_estudiante(env):\n",
    "    conn = conectar_bd(env)\n",
    "    sql_query = \"\"\"\n",
    "        select\n",
    "            s.estu_consecutivo,\n",
    "            s.periodo,\n",
    "            s.cole_cod_dane_establecimiento,\n",
    "            s.estu_fechanacimiento,\n",
    "            s.estu_genero,\n",
    "            s.fami_estratovivienda,\n",
    "            s.fami_tieneinternet,\n",
    "            s.fami_tienecomputador,\n",
    "            s.fami_educacionmadre,\n",
    "            s.fami_educacionpadre,\n",
    "            s.punt_ingles,\n",
    "            s.punt_matematicas,\n",
    "            s.punt_sociales_ciudadanas,\n",
    "            s.punt_c_naturales,\n",
    "            s.punt_lectura_critica,\n",
    "            s.punt_global\n",
    "        from\n",
    "            saber_11 s;\n",
    "      \"\"\"\n",
    "    datos_estudiante = pd.read_sql_query(sql_query, con=conn)\n",
    "\n",
    "    conn.dispose()\n",
    "    return datos_estudiante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `nivel_educacion_maximo` se encarga de obtener el nivel educativo máximo de los padres de los estudiantes. Para ello, se crea una lista con los niveles educativos en orden jerárquico y se asigna un valor numérico a cada uno según su índice. Luego, se obtiene el nivel educativo máximo de los padres de los estudiantes y se asigna el valor correspondiente. Esta función no se decoró con `@task` ya que es un proceso inidividual por cada registro de los estudiantes, lo cual no es significativo para el análisis del flujo de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nivel_educacion_maximo(row):\n",
    "    education_levels = [\n",
    "        \"Ninguno\",\n",
    "        \"Primaria incompleta\",\n",
    "        \"Primaria completa\",\n",
    "        \"Secundaria (Bachillerato) incompleta\",\n",
    "        \"Secundaria (Bachillerato) completa\",\n",
    "        \"Técnica o tecnológica incompleta\",\n",
    "        \"Técnica o tecnológica completa\",\n",
    "        \"Educación profesional incompleta\",\n",
    "        \"Educación profesional completa\",\n",
    "        \"Postgrado\",\n",
    "    ]\n",
    "\n",
    "    levels = [row[\"fami_educacionmadre\"], row[\"fami_educacionpadre\"]]\n",
    "\n",
    "    levels = [level for level in levels if level in education_levels]\n",
    "\n",
    "    if levels:\n",
    "        return max(levels, key=lambda level: education_levels.index(level))\n",
    "    return \"Ninguno\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo el flujo, tenemos la función `limpiar_datos_estudiantes`, la cual se encarga de limpiar los datos de los estudiantes. Se eliminan las columnas que no son relevantes para el análisis y se renombran las columnas restantes. Esta función se decoró con `@task` para que sea reconocida por Prefect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def limpiar_datos_estudiantes(datos_estudiante):\n",
    "    datos_estudiante = datos_estudiante[\n",
    "        datos_estudiante[\"estu_genero\"].isin([\"F\", \"M\"])\n",
    "    ]\n",
    "\n",
    "    datos_estudiante[\"fami_estratovivienda\"] = datos_estudiante[\n",
    "        \"fami_estratovivienda\"\n",
    "    ].replace(\"\", \"Sin Estrato\")\n",
    "\n",
    "    datos_estudiante = datos_estudiante[\n",
    "        datos_estudiante[\"fami_tieneinternet\"].isin([\"Si\", \"No\"])\n",
    "    ]\n",
    "\n",
    "    datos_estudiante[\"nivel_educacion_maximo\"] = datos_estudiante.apply(\n",
    "        nivel_educacion_maximo, axis=1\n",
    "    )\n",
    "\n",
    "    return datos_estudiante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos obteniendo el promedio de puntaje global por periodo, naturaleza y jornada del colegio con la función `promedio_puntaje_periodo`. Para ello, se realiza un merge entre los DataFrames `datos_colegio` y `datos_estudiante` y se agrupa por periodo, naturaleza y jornada. Se calcula el promedio del puntaje global y el número de estudiantes por grupo. Esta función se decoró con `@task` para que sea reconocida por Prefect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promedio_puntaje_periodo(datos_colegio, datos_estudiante):\n",
    "    merged_data = pd.merge(\n",
    "        datos_estudiante,\n",
    "        datos_colegio,\n",
    "        on=\"cole_cod_dane_establecimiento\",\n",
    "        how=\"inner\",\n",
    "        validate=\"m:m\",\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        merged_data.groupby([\"periodo\", \"cole_naturaleza\", \"cole_jornada\"])\n",
    "        .agg(\n",
    "            prom_punt_global=(\"punt_global\", \"mean\"),\n",
    "            numero_estudiantes=(\"punt_global\", \"size\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera similar, la función `promedio_puntaje_genero` se encarga de obtener el promedio de puntaje global por género. Se realiza un merge entre los DataFrames `datos_colegio` y `datos_estudiante` y se agrupa por género. Se calcula el promedio del puntaje global y el número de estudiantes por grupo. Esta función se decoró con `@task` para que sea reconocida por Prefect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def promedio_puntaje_genero(datos_colegio, datos_estudiante):\n",
    "    merged_data = pd.merge(\n",
    "        datos_estudiante,\n",
    "        datos_colegio,\n",
    "        on=\"cole_cod_dane_establecimiento\",\n",
    "        how=\"inner\",\n",
    "        validate=\"m:m\",\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        merged_data.groupby([\"estu_genero\", \"cole_naturaleza\", \"cole_jornada\"])\n",
    "        .agg(\n",
    "            prom_punt_global=(\"punt_global\", \"mean\"),\n",
    "            numero_estudiantes=(\"punt_global\", \"size\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un análisis similar con la función `promedio_puntaje_estrato`, la cual obtiene el promedio de puntaje global por estrato socioeconómico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def promedio_puntaje_estrato(datos_colegio, datos_estudiante):\n",
    "    merged_data = pd.merge(\n",
    "        datos_estudiante,\n",
    "        datos_colegio,\n",
    "        on=\"cole_cod_dane_establecimiento\",\n",
    "        how=\"inner\",\n",
    "        validate=\"m:m\",\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        merged_data.groupby([\"fami_estratovivienda\", \"cole_naturaleza\", \"cole_jornada\"])\n",
    "        .agg(\n",
    "            prom_punt_global=(\"punt_global\", \"mean\"),\n",
    "            numero_estudiantes=(\"punt_global\", \"size\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuando con la transformación de los datos, la función `promedio_puntaje_internet` se encarga de obtener el promedio de puntaje global por acceso a internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def promedio_puntaje_internet(datos_colegio, datos_estudiante):\n",
    "    merged_data = pd.merge(\n",
    "        datos_estudiante,\n",
    "        datos_colegio,\n",
    "        on=\"cole_cod_dane_establecimiento\",\n",
    "        how=\"inner\",\n",
    "        validate=\"m:m\",\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        merged_data.groupby([\"fami_tieneinternet\", \"cole_naturaleza\", \"cole_jornada\"])\n",
    "        .agg(\n",
    "            prom_punt_global=(\"punt_global\", \"mean\"),\n",
    "            numero_estudiantes=(\"punt_global\", \"size\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, la función `promedio_puntaje_educacion_familia` se encarga de obtener el promedio de puntaje global por nivel educativo de la familia. Esta función utiliza la columna generada en la función `nivel_educacion_maximo` para agrupar los datos y calcular el promedio del puntaje global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def promedio_puntaje_educacion_familia(datos_colegio, datos_estudiante):\n",
    "    merged_data = pd.merge(\n",
    "        datos_estudiante,\n",
    "        datos_colegio,\n",
    "        on=\"cole_cod_dane_establecimiento\",\n",
    "        how=\"inner\",\n",
    "        validate=\"m:m\",\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        merged_data.groupby(\n",
    "            [\"nivel_educacion_maximo\", \"cole_naturaleza\", \"cole_jornada\"]\n",
    "        )\n",
    "        .agg(\n",
    "            prom_punt_global=(\"punt_global\", \"mean\"),\n",
    "            numero_estudiantes=(\"punt_global\", \"size\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Para el proceso de carga de datos se hizo uso de ORM con la librería SQLAlchemy para organizar los datos estudiados en un modelo objeto-relacional. Para esto se crean las clases que se encargaran de definir las tablas con la información que se quiere cargar y definiendo cada uno de los atributos internos y los tipos de datos. Seguido a esto se define una función que devuelve un objeto a la conexión con la base de datos y otra función para la creación todas las tablas definidas.\n",
    "\n",
    "Finalmente para la carga masiva de datos se realiza la insersión de estos utilizando el método try finally para asegurar una correcta ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "@task\n",
    "def cargar_tablas_analitica(\n",
    "    env,\n",
    "    datos_colegio,\n",
    "    puntaje_periodo,\n",
    "    puntaje_genero,\n",
    "    puntaje_estrato,\n",
    "    puntaje_internet,\n",
    "    puntaje_educacion_familia,\n",
    "):\n",
    "    class AnaliticaColegio(Base):\n",
    "        __tablename__ = \"analitica_colegio\"\n",
    "\n",
    "        id = sa.Column(sa.Integer, primary_key=True)\n",
    "        cole_cod_dane_establecimiento = sa.Column(sa.String)\n",
    "        cole_jornada = sa.Column(sa.String)\n",
    "        cole_naturaleza = sa.Column(sa.String)\n",
    "        cole_calendario = sa.Column(sa.String)\n",
    "        cole_nombre_establecimiento = sa.Column(sa.String)\n",
    "        cole_caracter = sa.Column(sa.String)\n",
    "        cole_area_ubicacion = sa.Column(sa.String)\n",
    "        cole_genero = sa.Column(sa.String)\n",
    "        prom_punt_global = sa.Column(sa.Float)\n",
    "\n",
    "        def _repr_(self):\n",
    "            return f\"AnaliticaColegio(id={self.id!r}, cole_cod_dane_establecimiento={self.cole_cod_dane_establecimiento!r}, \\\n",
    "                    cole_jornada = {self.cole_jornada!r}, cole_naturaleza = {self.cole_naturaleza!r}, cole_calendario = {self.cole_calendario!r}, \\\n",
    "                    cole_nombre_establecimiento = {self.cole_nombre_establecimiento!r}, cole_caracter = {self.cole_caracter!r}, \\\n",
    "                    cole_area_ubicacion = {self.cole_area_ubicacion!r}, cole_genero = {self.cole_genero!r}, prom_punt_global = {self.prom_punt_global!r}\"\n",
    "\n",
    "    class AnaliticaPuntajePeriodo(Base):\n",
    "        __tablename__ = \"analitica_puntaje_periodo\"\n",
    "\n",
    "        id = sa.Column(sa.Integer, primary_key=True)\n",
    "        periodo = sa.Column(sa.Integer)\n",
    "        cole_naturaleza = sa.Column(sa.String)\n",
    "        cole_jornada = sa.Column(sa.String)\n",
    "        prom_punt_global = sa.Column(sa.Float)\n",
    "        numero_estudiantes = sa.Column(sa.Integer)\n",
    "\n",
    "        def _repr_(self):\n",
    "            return f\"AnaliticaPuntajePeriodo(id={self.id!r}, periodo={self.periodo!r}, cole_naturaleza={self.cole_naturaleza!r}, \\\n",
    "                    cole_jornada = {self.cole_jornada!r}, prom_punt_global = {self.prom_punt_global!r}, numero_estudiantes = {self.numero_estudiantes!r}\"\n",
    "\n",
    "    class AnaliticaPuntajeGenero(Base):\n",
    "        __tablename__ = \"analitica_puntaje_genero\"\n",
    "\n",
    "        id = sa.Column(sa.Integer, primary_key=True)\n",
    "        estu_genero = sa.Column(sa.String)\n",
    "        cole_naturaleza = sa.Column(sa.String)\n",
    "        cole_jornada = sa.Column(sa.String)\n",
    "        prom_punt_global = sa.Column(sa.Float)\n",
    "        numero_estudiantes = sa.Column(sa.Integer)\n",
    "\n",
    "        def _repr_(self):\n",
    "            return f\"AnaliticaPuntajeGenero(id={self.id!r}, estu_genero={self.estu_genero!r}, cole_naturaleza={self.cole_naturaleza!r}, \\\n",
    "                    cole_jornada = {self.cole_jornada!r}, prom_punt_global = {self.prom_punt_global!r}, numero_estudiantes = {self.numero_estudiantes!r}\"\n",
    "\n",
    "    class AnaliticaPuntajeEstrato(Base):\n",
    "        __tablename__ = \"analitica_puntaje_estrato\"\n",
    "\n",
    "        id = sa.Column(sa.Integer, primary_key=True)\n",
    "        fami_estratovivienda = sa.Column(sa.String)\n",
    "        cole_naturaleza = sa.Column(sa.String)\n",
    "        cole_jornada = sa.Column(sa.String)\n",
    "        prom_punt_global = sa.Column(sa.Float)\n",
    "        numero_estudiantes = sa.Column(sa.Integer)\n",
    "\n",
    "        def _repr_(self):\n",
    "            return f\"AnaliticaPuntajeEstrato(id={self.id!r}, fami_estratovivienda={self.fami_estratovivienda!r}, cole_naturaleza={self.cole_naturaleza!r}, \\\n",
    "                    cole_jornada = {self.cole_jornada!r}, prom_punt_global = {self.prom_punt_global!r}, numero_estudiantes = {self.numero_estudiantes!r}\"\n",
    "\n",
    "    class AnaliticaPuntajeInternet(Base):\n",
    "        __tablename__ = \"analitica_puntaje_internet\"\n",
    "\n",
    "        id = sa.Column(sa.Integer, primary_key=True)\n",
    "        fami_tieneinternet = sa.Column(sa.String)\n",
    "        cole_naturaleza = sa.Column(sa.String)\n",
    "        cole_jornada = sa.Column(sa.String)\n",
    "        prom_punt_global = sa.Column(sa.Float)\n",
    "        numero_estudiantes = sa.Column(sa.Integer)\n",
    "\n",
    "        def _repr_(self):\n",
    "            return f\"AnaliticaPuntajeInternet(id={self.id!r}, fami_tieneinternet={self.fami_tieneinternet!r}, cole_naturaleza={self.cole_naturaleza!r}, \\\n",
    "                    cole_jornada = {self.cole_jornada!r}, prom_punt_global = {self.prom_punt_global!r}, numero_estudiantes = {self.numero_estudiantes!r}\"\n",
    "\n",
    "    class AnaliticaEducacionFamilia(Base):\n",
    "        __tablename__ = \"analitica_educacion_familia\"\n",
    "\n",
    "        id = sa.Column(sa.Integer, primary_key=True)\n",
    "        nivel_educacion_maximo = sa.Column(sa.String)\n",
    "        cole_naturaleza = sa.Column(sa.String)\n",
    "        cole_jornada = sa.Column(sa.String)\n",
    "        prom_punt_global = sa.Column(sa.Float)\n",
    "        numero_estudiantes = sa.Column(sa.Integer)\n",
    "\n",
    "        def _repr_(self):\n",
    "            return f\"AnaliticaEducacionFamilia(id={self.id!r}, nivel_educacion_maximo={self.nivel_educacion_maximo!r}, cole_naturaleza={self.cole_naturaleza!r}, \\\n",
    "                    cole_jornada = {self.cole_jornada!r}, prom_punt_global = {self.prom_punt_global!r}, numero_estudiantes = {self.numero_estudiantes!r}\"\n",
    "\n",
    "    conn = conectar_bd(env)\n",
    "\n",
    "    Base.metadata.create_all(conn)\n",
    "\n",
    "    try:\n",
    "        with Session(conn) as session:\n",
    "            session.bulk_insert_mappings(\n",
    "                AnaliticaColegio, datos_colegio.to_dict(orient=\"records\")\n",
    "            )\n",
    "            session.bulk_insert_mappings(\n",
    "                AnaliticaPuntajePeriodo, puntaje_periodo.to_dict(orient=\"records\")\n",
    "            )\n",
    "            session.bulk_insert_mappings(\n",
    "                AnaliticaPuntajeGenero, puntaje_genero.to_dict(orient=\"records\")\n",
    "            )\n",
    "            session.bulk_insert_mappings(\n",
    "                AnaliticaPuntajeEstrato, puntaje_estrato.to_dict(orient=\"records\")\n",
    "            )\n",
    "            session.bulk_insert_mappings(\n",
    "                AnaliticaPuntajeInternet, puntaje_internet.to_dict(orient=\"records\")\n",
    "            )\n",
    "            session.bulk_insert_mappings(\n",
    "                AnaliticaEducacionFamilia,\n",
    "                puntaje_educacion_familia.to_dict(orient=\"records\"),\n",
    "            )\n",
    "            session.commit()\n",
    "    finally:\n",
    "        conn.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilando todo en la función `flujo_analitica`, se orquesta el flujo de trabajo completo. Se obtienen los datos de los colegios y los estudiantes, se limpian los datos de los estudiantes, se realizan los cálculos de los promedios de puntaje global por diferentes variables y se cargan los resultados en la base de datos de AWS. Al finalizar el proceso, se imprime un mensaje indicando que el proceso ETL ha finalizado. Esta función se decoró con `@flow` para que sea reconocida por Prefect como el inicializador de todo el flujo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow(name=\"proyecto_grupal\", log_prints=True)\n",
    "def flujo_analitica():\n",
    "    datos_colegio = obtener_datos_colegio(\"local\")\n",
    "    datos_estudiante = obtener_datos_estudiante(\"local\")\n",
    "\n",
    "    datos_estudiante = limpiar_datos_estudiantes(datos_estudiante)\n",
    "\n",
    "    puntaje_periodo = promedio_puntaje_periodo(datos_colegio, datos_estudiante)\n",
    "    puntaje_genero = promedio_puntaje_genero(datos_colegio, datos_estudiante)\n",
    "    puntaje_estrato = promedio_puntaje_estrato(datos_colegio, datos_estudiante)\n",
    "    puntaje_internet = promedio_puntaje_internet(datos_colegio, datos_estudiante)\n",
    "    puntaje_educacion_familia = promedio_puntaje_educacion_familia(\n",
    "        datos_colegio, datos_estudiante\n",
    "    )\n",
    "\n",
    "    cargar_tablas_analitica(\n",
    "        \"aws\",\n",
    "        datos_colegio,\n",
    "        puntaje_periodo,\n",
    "        puntaje_genero,\n",
    "        puntaje_estrato,\n",
    "        puntaje_internet,\n",
    "        puntaje_educacion_familia,\n",
    "    )\n",
    "\n",
    "    print(\"ETL process finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se ejecuta el flujo de trabajo con la función `flujo_analitica()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flujo_analitica()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
